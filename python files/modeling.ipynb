{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data locations(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_features_list = ['features/'+i for i in os.listdir('features')]\n",
    "path_to_extra_features_list = ['extra_features/'+i for i in os.listdir('extra_features')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build classifier grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_parallel_models = 45\n",
    "\n",
    "#SVM\n",
    "classifier_svc = SVC()\n",
    "parameters_svc = {\n",
    "    'kernel': ('linear', 'rbf')\n",
    "}\n",
    "grid_search_svc = GridSearchCV(classifier_svc, parameters_svc, n_jobs=number_of_parallel_models)\n",
    "\n",
    "#SGDClassifier\n",
    "classifier_sgd = SGDClassifier()\n",
    "parameters_sgd = {\n",
    "    'loss': ('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', \n",
    "                  'squared_loss', 'huber', 'epsilon_insensitive',  'squared_epsilon_insensitive'),\n",
    "    'penalty': ('l1', 'l2'),\n",
    "    'learning_rate': ('constant', 'optimal', 'invscaling'),\n",
    "    'eta0': tuple([10**(-i) for i in range(2, 5)]),\n",
    "}\n",
    "grid_search_sgd = GridSearchCV(classifier_sgd, parameters_sgd, n_jobs=number_of_parallel_models)\n",
    "\n",
    "#MultinomialNB\n",
    "classifier_mnb = MultinomialNB()\n",
    "parameters_mnb = {}\n",
    "grid_search_mnb = GridSearchCV(classifier_mnb, parameters_mnb, n_jobs=number_of_parallel_models)\n",
    "\n",
    "#GaussianNB\n",
    "classifier_gnb = GaussianNB()\n",
    "parameters_gnb = {}\n",
    "grid_search_gnb = GridSearchCV(classifier_gnb, parameters_gnb, n_jobs=number_of_parallel_models)\n",
    "\n",
    "\n",
    "#GradientBoostingClassifier\n",
    "classifier_gbc = GradientBoostingClassifier()\n",
    "parameters_gbc = {\n",
    "    'loss': ('deviance', 'exponential'),\n",
    "    'learning_rate':  tuple([10**(-i) for i in range(2, 5)]),\n",
    "    'n_estimators': tuple([10**i for i in range(2, 4)]),\n",
    "    'max_depth': tuple(range(2,7)),\n",
    "}\n",
    "grid_search_gbc = GridSearchCV(classifier_gbc, parameters_gbc, n_jobs=number_of_parallel_models)\n",
    "\n",
    "\n",
    "#AdaBoostClassifier\n",
    "classifier_abc = AdaBoostClassifier()\n",
    "parameters_abc = {\n",
    "    'n_estimators': tuple(range(10, 101, 10)),\n",
    "    'learning_rate': tuple([10**(-i) for i in range(1, 5)]),\n",
    "}\n",
    "grid_search_abc = GridSearchCV(classifier_abc, parameters_abc, n_jobs=number_of_parallel_models)\n",
    "\n",
    "\n",
    "#RandomForestClassifier\n",
    "classifier_rfc = RandomForestClassifier()\n",
    "parameters_rfc = {\n",
    "    'n_estimators': tuple(range(10, 101, 10)),\n",
    "    'criterion': ('gini', 'entropy'),\n",
    "    'n_jobs': (5,)    \n",
    "}\n",
    "grid_search_rfc = GridSearchCV(classifier_rfc, parameters_rfc, n_jobs=number_of_parallel_models)\n",
    "\n",
    "\n",
    "#DecisionTreeClassifier\n",
    "classifier_dtc = DecisionTreeClassifier()\n",
    "parameters_dtc = {\n",
    "    'criterion': ('gini', 'entropy'),\n",
    "}\n",
    "grid_search_dtc = GridSearchCV(classifier_dtc, parameters_dtc, n_jobs=number_of_parallel_models)\n",
    "\n",
    "\n",
    "#GaussianProcessClassifier\n",
    "classifier_gpc = GaussianProcessClassifier()\n",
    "parameters_gpc = {}\n",
    "grid_search_gpc = GridSearchCV(classifier_gpc, parameters_gpc, n_jobs=number_of_parallel_models)\n",
    "\n",
    "\n",
    "#KNeighborsClassifier\n",
    "classifier_knc = KNeighborsClassifier()\n",
    "parameters_knc = {\n",
    "    'n_neighbors': tuple(range(1,9)),\n",
    "}\n",
    "grid_search_knc = GridSearchCV(classifier_knc, parameters_knc, n_jobs=number_of_parallel_models)\n",
    "\n",
    "\n",
    "#MLPClassifier \n",
    "# classifier_mlp = MLPClassifier()\n",
    "# parameters_mlp = {\n",
    "#     'hidden_layer_sizes' : [(max_num//2,), (max_num,), (max_num*2,), (max_num*4,), \n",
    "#                      (max_num//2,max_num//2), (max_num,max_num//2), \n",
    "#                       (max_num*2, max_num//2), (max_num*4, max_num//2)],\n",
    "# \t'activation' : ('identity', 'logistic', 'tanh', 'relu'),\n",
    "# \t'solver' : ['sgd', 'adam'],\n",
    "# \t'alpha' : [10**(-i) for i in range(1, 5, 2)],\n",
    "# \t'batch_size' : [50, 150, 250, 350],\n",
    "# \t'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "# \t'learning_rate_init' : [10**(-i) for i in range(1, 5, 2)],\n",
    "# \t'max_iter' : [500, 1000, 2000]\n",
    "# }\n",
    "# grid_search_mlp = GridSearchCV(classifier_mlp, parameters_mlp, n_jobs=number_of_parallel_models)\n",
    "\n",
    "#list of grid_objects\n",
    "grid_search_dict = {\n",
    "    'SVM_linear': SVC(C=1, kernel='linear'),\n",
    "#     'SVM_rbf': SVC(C=25, kernel='rbf')\n",
    "#     'SVM': grid_search_svc,\n",
    "#     'Ada Boost': grid_search_abc,\n",
    "#     'Decision Tree': grid_search_dtc,\n",
    "#     'Gradient Boost': grid_search_gbc,\n",
    "#     'Gausian Naive Bayes': grid_search_gnb,\n",
    "#     'Gaussian Process': grid_search_gpc,\n",
    "#     'K Nearest Neighbours': grid_search_knc,\n",
    "#     'Multinomial Naive Bayes': grid_search_mnb,\n",
    "#     'Random Forest': grid_search_rfc,\n",
    "#     'Stochastic Gradient Descent': grid_search_sgd,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN models and save accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "force = True\n",
    "\n",
    "# path_to_extra_features_list = []\n",
    "\n",
    "for path in list(path_to_extra_features_list+path_to_features_list):\n",
    "    #load data\n",
    "    path_to_write = 'results/SVM_updated/'+path.split('/')[1]\n",
    "    if os.path.isfile(path_to_write) and not force:\n",
    "        print(path, \"already exists. Moving on........\\n\\n\")\n",
    "        continue\n",
    "    data = pickle.load(open(path, 'rb'))\n",
    "    X_train = data['X_train'].toarray()\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test'].toarray()\n",
    "    y_test = data['y_test']\n",
    "    print(\"Loaded\", path)\n",
    "    evaluation_dict = {'Criteria': ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 score', 'Confusion Matrix']}\n",
    "    for grid in grid_search_dict:\n",
    "        model = grid_search_dict[grid]\n",
    "        print(\"\\n\\tAttempting\", grid)\n",
    "        %time model.fit(X_train, y_train)\n",
    "        print(\"\\t\\tFinished fitting\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"\\t\\tFinished predicting\")\n",
    "        evaluation_dict[grid] = [\n",
    "                                model,\n",
    "                                accuracy_score(y_test, y_pred),\n",
    "                                precision_score(y_test, y_pred, average='weighted'),\n",
    "                                recall_score(y_test, y_pred, average='weighted'),\n",
    "                                f1_score(y_test, y_pred, average='weighted'),\n",
    "                                confusion_matrix(y_test, y_pred)\n",
    "                                ]\n",
    "        print(\"\\t\\tFinished evaluating!\")\n",
    "    pickle.dump(evaluation_dict, open(path_to_write, 'wb'))\n",
    "    print(\"Dumping successful!!!!!!!!\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
