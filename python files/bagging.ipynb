{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import os\n",
    "from scipy.sparse import hstack\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('max_colwidth',60)\n",
    "\n",
    "metric_dump_file = 'metric_table.pickle'\n",
    "if os.path.isfile(metric_dump_file):\n",
    "    table_matrix = pd.DataFrame.from_dict(pickle.load(open(metric_dump_file, 'rb')))\n",
    "    del metric_dump_file\n",
    "else:\n",
    "    raise Exception(str(\"File \" + metric_dump_file + \" NOT FOUND!!\"))\n",
    "    \n",
    "table_matrix = table_matrix[['Feature', 'Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 score', 'Confusion Matrix']]\n",
    "a = table_matrix['Confusion Matrix']\n",
    "table_matrix['True Count'] = list(map(lambda x: x[0][0] + x[1][1] + x[2][2], a))\n",
    "def feature_type(stringy):\n",
    "    splity = stringy.split('_')\n",
    "    if splity[-1] == 'alphabet':\n",
    "        return 'punctuation'\n",
    "    if splity[0] == 'capitals':\n",
    "        return 'capital'\n",
    "    if 'char' in splity:\n",
    "        return 'character'\n",
    "    return 'word'\n",
    "table_matrix['Feature type'] = list(map(feature_type, table_matrix['Feature']))\n",
    "del a\n",
    "# display(table_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top char n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_type = 'SVM'\n",
    "top_number = 4\n",
    "evaluation_critera = 'F1 score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>True Count</th>\n",
       "      <th>Feature type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1-5_char_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.585472</td>\n",
       "      <td>0.588197</td>\n",
       "      <td>0.585472</td>\n",
       "      <td>0.579502</td>\n",
       "      <td>[[875, 292, 66], [329, 614, 114], [138, 305, 268]]</td>\n",
       "      <td>1757</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1-6_char_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.582139</td>\n",
       "      <td>0.585279</td>\n",
       "      <td>0.582139</td>\n",
       "      <td>0.576301</td>\n",
       "      <td>[[871, 300, 62], [334, 607, 116], [144, 298, 269]]</td>\n",
       "      <td>1747</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2-5_char_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.580140</td>\n",
       "      <td>0.580481</td>\n",
       "      <td>0.580140</td>\n",
       "      <td>0.574088</td>\n",
       "      <td>[[876, 292, 65], [331, 596, 130], [150, 292, 269]]</td>\n",
       "      <td>1741</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2-6_char_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.577807</td>\n",
       "      <td>0.579623</td>\n",
       "      <td>0.577807</td>\n",
       "      <td>0.571627</td>\n",
       "      <td>[[869, 303, 61], [333, 600, 124], [155, 291, 265]]</td>\n",
       "      <td>1734</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Classifier  Accuracy  Precision    Recall  F1 score  \\\n",
       "126  1-5_char_gram        SVM  0.585472   0.588197  0.585472  0.579502   \n",
       "124  1-6_char_gram        SVM  0.582139   0.585279  0.582139  0.576301   \n",
       "97   2-5_char_gram        SVM  0.580140   0.580481  0.580140  0.574088   \n",
       "88   2-6_char_gram        SVM  0.577807   0.579623  0.577807  0.571627   \n",
       "\n",
       "                                       Confusion Matrix  True Count  \\\n",
       "126  [[875, 292, 66], [329, 614, 114], [138, 305, 268]]        1757   \n",
       "124  [[871, 300, 62], [334, 607, 116], [144, 298, 269]]        1747   \n",
       "97   [[876, 292, 65], [331, 596, 130], [150, 292, 269]]        1741   \n",
       "88   [[869, 303, 61], [333, 600, 124], [155, 291, 265]]        1734   \n",
       "\n",
       "    Feature type  \n",
       "126    character  \n",
       "124    character  \n",
       "97     character  \n",
       "88     character  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_char_features = table_matrix[(table_matrix['Classifier']==classifier_type) & (table_matrix['Feature type']=='character')].sort_values(evaluation_critera, ascending=False).head(top_number)\n",
    "top_char_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top word n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>True Count</th>\n",
       "      <th>Feature type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1-2_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.576141</td>\n",
       "      <td>0.576790</td>\n",
       "      <td>0.576141</td>\n",
       "      <td>0.569729</td>\n",
       "      <td>[[872, 295, 66], [329, 599, 129], [142, 311, 258]]</td>\n",
       "      <td>1729</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1-4_gram_without_stopwords</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.571809</td>\n",
       "      <td>0.570333</td>\n",
       "      <td>0.571809</td>\n",
       "      <td>0.564258</td>\n",
       "      <td>[[874, 289, 70], [334, 593, 130], [159, 303, 249]]</td>\n",
       "      <td>1716</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1-2_gram_without_stopwords</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.571143</td>\n",
       "      <td>0.570002</td>\n",
       "      <td>0.571143</td>\n",
       "      <td>0.563551</td>\n",
       "      <td>[[873, 291, 69], [337, 592, 128], [161, 301, 249]]</td>\n",
       "      <td>1714</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>unigram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.570477</td>\n",
       "      <td>0.571231</td>\n",
       "      <td>0.570477</td>\n",
       "      <td>0.563347</td>\n",
       "      <td>[[872, 301, 60], [341, 588, 128], [154, 305, 252]]</td>\n",
       "      <td>1712</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature Classifier  Accuracy  Precision    Recall  \\\n",
       "115                    1-2_gram        SVM  0.576141   0.576790  0.576141   \n",
       "130  1-4_gram_without_stopwords        SVM  0.571809   0.570333  0.571809   \n",
       "120  1-2_gram_without_stopwords        SVM  0.571143   0.570002  0.571143   \n",
       "116                     unigram        SVM  0.570477   0.571231  0.570477   \n",
       "\n",
       "     F1 score                                    Confusion Matrix  True Count  \\\n",
       "115  0.569729  [[872, 295, 66], [329, 599, 129], [142, 311, 258]]        1729   \n",
       "130  0.564258  [[874, 289, 70], [334, 593, 130], [159, 303, 249]]        1716   \n",
       "120  0.563551  [[873, 291, 69], [337, 592, 128], [161, 301, 249]]        1714   \n",
       "116  0.563347  [[872, 301, 60], [341, 588, 128], [154, 305, 252]]        1712   \n",
       "\n",
       "    Feature type  \n",
       "115         word  \n",
       "130         word  \n",
       "120         word  \n",
       "116         word  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_word_features = table_matrix[(table_matrix['Classifier']==classifier_type) & (table_matrix['Feature type']=='word')].sort_values(evaluation_critera, ascending=False).head(top_number)\n",
    "display(top_word_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top punctuation n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>True Count</th>\n",
       "      <th>Feature type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>char_2_gram_non_alphabet</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.425858</td>\n",
       "      <td>0.364967</td>\n",
       "      <td>0.425858</td>\n",
       "      <td>0.333259</td>\n",
       "      <td>[[1059, 171, 3], [834, 217, 6], [571, 138, 2]]</td>\n",
       "      <td>1278</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>char_3_gram_non_alphabet</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.422859</td>\n",
       "      <td>0.373381</td>\n",
       "      <td>0.422859</td>\n",
       "      <td>0.326939</td>\n",
       "      <td>[[1082, 136, 15], [863, 176, 18], [558, 142, 11]]</td>\n",
       "      <td>1269</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>char_1_gram_non_alphabet</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.426524</td>\n",
       "      <td>0.392286</td>\n",
       "      <td>0.426524</td>\n",
       "      <td>0.324395</td>\n",
       "      <td>[[1100, 129, 4], [874, 176, 7], [610, 97, 4]]</td>\n",
       "      <td>1280</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>char_4_gram_non_alphabet</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.421193</td>\n",
       "      <td>0.402914</td>\n",
       "      <td>0.421193</td>\n",
       "      <td>0.320690</td>\n",
       "      <td>[[1099, 113, 21], [898, 146, 13], [593, 99, 19]]</td>\n",
       "      <td>1264</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature Classifier  Accuracy  Precision    Recall  \\\n",
       "66  char_2_gram_non_alphabet        SVM  0.425858   0.364967  0.425858   \n",
       "1   char_3_gram_non_alphabet        SVM  0.422859   0.373381  0.422859   \n",
       "21  char_1_gram_non_alphabet        SVM  0.426524   0.392286  0.426524   \n",
       "71  char_4_gram_non_alphabet        SVM  0.421193   0.402914  0.421193   \n",
       "\n",
       "    F1 score                                   Confusion Matrix  True Count  \\\n",
       "66  0.333259     [[1059, 171, 3], [834, 217, 6], [571, 138, 2]]        1278   \n",
       "1   0.326939  [[1082, 136, 15], [863, 176, 18], [558, 142, 11]]        1269   \n",
       "21  0.324395      [[1100, 129, 4], [874, 176, 7], [610, 97, 4]]        1280   \n",
       "71  0.320690   [[1099, 113, 21], [898, 146, 13], [593, 99, 19]]        1264   \n",
       "\n",
       "   Feature type  \n",
       "66  punctuation  \n",
       "1   punctuation  \n",
       "21  punctuation  \n",
       "71  punctuation  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_punctuation_features = table_matrix[(table_matrix['Classifier']==classifier_type) & (table_matrix['Feature type']=='punctuation')].sort_values(evaluation_critera, ascending=False).head(top_number)\n",
    "display(top_punctuation_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top capital n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>True Count</th>\n",
       "      <th>Feature type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>capitals_char_2_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.422526</td>\n",
       "      <td>0.422978</td>\n",
       "      <td>0.422526</td>\n",
       "      <td>0.312094</td>\n",
       "      <td>[[1134, 83, 16], [936, 107, 14], [597, 87, 27]]</td>\n",
       "      <td>1268</td>\n",
       "      <td>capital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>capitals_char_3_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.427857</td>\n",
       "      <td>0.431222</td>\n",
       "      <td>0.427857</td>\n",
       "      <td>0.310054</td>\n",
       "      <td>[[1163, 57, 13], [946, 96, 15], [603, 83, 25]]</td>\n",
       "      <td>1284</td>\n",
       "      <td>capital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>capitals_char_1_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.415861</td>\n",
       "      <td>0.307224</td>\n",
       "      <td>0.415861</td>\n",
       "      <td>0.307479</td>\n",
       "      <td>[[1099, 134, 0], [908, 149, 0], [603, 108, 0]]</td>\n",
       "      <td>1248</td>\n",
       "      <td>capital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>capitals_char_4_gram</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.415861</td>\n",
       "      <td>0.430207</td>\n",
       "      <td>0.415861</td>\n",
       "      <td>0.257282</td>\n",
       "      <td>[[1222, 6, 5], [1033, 16, 8], [687, 14, 10]]</td>\n",
       "      <td>1248</td>\n",
       "      <td>capital</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature Classifier  Accuracy  Precision    Recall  F1 score  \\\n",
       "36  capitals_char_2_gram        SVM  0.422526   0.422978  0.422526  0.312094   \n",
       "11  capitals_char_3_gram        SVM  0.427857   0.431222  0.427857  0.310054   \n",
       "6   capitals_char_1_gram        SVM  0.415861   0.307224  0.415861  0.307479   \n",
       "41  capitals_char_4_gram        SVM  0.415861   0.430207  0.415861  0.257282   \n",
       "\n",
       "                                   Confusion Matrix  True Count Feature type  \n",
       "36  [[1134, 83, 16], [936, 107, 14], [597, 87, 27]]        1268      capital  \n",
       "11   [[1163, 57, 13], [946, 96, 15], [603, 83, 25]]        1284      capital  \n",
       "6    [[1099, 134, 0], [908, 149, 0], [603, 108, 0]]        1248      capital  \n",
       "41     [[1222, 6, 5], [1033, 16, 8], [687, 14, 10]]        1248      capital  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_capital_features = table_matrix[(table_matrix['Classifier']==classifier_type) & (table_matrix['Feature type']=='capital')].sort_values(evaluation_critera, ascending=False).head(top_number)\n",
    "display(top_capital_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test labels for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1510    1\n",
       "1802    1\n",
       "1740    2\n",
       "2878    1\n",
       "2719    3\n",
       "2704    3\n",
       "1160    1\n",
       "566     3\n",
       "1893    2\n",
       "26      1\n",
       "1941    1\n",
       "806     1\n",
       "2813    2\n",
       "1853    2\n",
       "819     1\n",
       "1026    3\n",
       "216     3\n",
       "1125    2\n",
       "2530    1\n",
       "1565    2\n",
       "449     3\n",
       "1666    3\n",
       "1691    2\n",
       "2635    1\n",
       "1486    2\n",
       "2020    1\n",
       "2657    2\n",
       "2936    1\n",
       "692     3\n",
       "2312    2\n",
       "821     2\n",
       "2662    1\n",
       "420     1\n",
       "2986    3\n",
       "2542    3\n",
       "505     2\n",
       "2127    2\n",
       "1634    1\n",
       "1245    1\n",
       "2188    1\n",
       "2470    2\n",
       "1970    3\n",
       "2346    1\n",
       "107     1\n",
       "2595    2\n",
       "551     2\n",
       "366     1\n",
       "2857    1\n",
       "1737    3\n",
       "661     1\n",
       "2209    2\n",
       "2830    3\n",
       "2116    2\n",
       "2502    2\n",
       "921     2\n",
       "2539    1\n",
       "2797    1\n",
       "1643    3\n",
       "845     1\n",
       "1693    1\n",
       "109     2\n",
       "1468    1\n",
       "2451    1\n",
       "1102    1\n",
       "1826    2\n",
       "21      3\n",
       "1701    2\n",
       "1332    2\n",
       "1817    1\n",
       "80      3\n",
       "892     3\n",
       "417     2\n",
       "2334    1\n",
       "173     2\n",
       "104     2\n",
       "1039    3\n",
       "2685    3\n",
       "940     3\n",
       "55      1\n",
       "646     2\n",
       "1684    2\n",
       "2133    2\n",
       "1193    1\n",
       "1519    1\n",
       "2787    2\n",
       "1985    1\n",
       "190     3\n",
       "2992    1\n",
       "2370    1\n",
       "1190    1\n",
       "975     1\n",
       "1900    1\n",
       "781     2\n",
       "1124    2\n",
       "761     2\n",
       "409     2\n",
       "2921    2\n",
       "827     2\n",
       "2434    3\n",
       "700     3\n",
       "1935    2\n",
       "445     2\n",
       "1323    1\n",
       "2071    2\n",
       "1128    2\n",
       "2644    1\n",
       "1690    1\n",
       "658     2\n",
       "1962    2\n",
       "1049    1\n",
       "1013    2\n",
       "1307    2\n",
       "2010    1\n",
       "1717    1\n",
       "227     1\n",
       "1541    1\n",
       "2141    2\n",
       "1582    3\n",
       "370     2\n",
       "205     2\n",
       "1061    2\n",
       "410     2\n",
       "2784    2\n",
       "1374    3\n",
       "1092    1\n",
       "1515    1\n",
       "2548    1\n",
       "723     1\n",
       "999     1\n",
       "446     2\n",
       "2809    2\n",
       "1917    1\n",
       "1476    2\n",
       "175     1\n",
       "378     1\n",
       "2353    2\n",
       "1805    1\n",
       "1418    1\n",
       "874     1\n",
       "354     2\n",
       "2785    2\n",
       "1894    2\n",
       "1997    1\n",
       "2403    3\n",
       "127     3\n",
       "2483    2\n",
       "1584    1\n",
       "2318    2\n",
       "2300    1\n",
       "1484    2\n",
       "538     1\n",
       "407     1\n",
       "1783    1\n",
       "1990    1\n",
       "1803    2\n",
       "1420    1\n",
       "1930    1\n",
       "391     1\n",
       "1204    2\n",
       "419     1\n",
       "1164    1\n",
       "17      2\n",
       "1187    2\n",
       "1423    3\n",
       "990     3\n",
       "2598    3\n",
       "98      2\n",
       "914     3\n",
       "134     1\n",
       "310     2\n",
       "1812    1\n",
       "497     3\n",
       "1154    1\n",
       "53      2\n",
       "2377    3\n",
       "1407    2\n",
       "212     1\n",
       "1322    1\n",
       "2868    2\n",
       "1294    2\n",
       "2037    2\n",
       "40      2\n",
       "1112    3\n",
       "288     2\n",
       "2551    1\n",
       "1284    3\n",
       "1098    2\n",
       "232     3\n",
       "2233    1\n",
       "1314    2\n",
       "664     1\n",
       "946     2\n",
       "2844    3\n",
       "330     1\n",
       "688     3\n",
       "2629    1\n",
       "1191    1\n",
       "1546    3\n",
       "2040    2\n",
       "2079    1\n",
       "2355    1\n",
       "2621    3\n",
       "1207    1\n",
       "489     1\n",
       "250     1\n",
       "1254    2\n",
       "1432    2\n",
       "1239    2\n",
       "2073    1\n",
       "958     2\n",
       "1085    3\n",
       "2316    1\n",
       "2863    3\n",
       "2131    2\n",
       "2653    1\n",
       "1021    2\n",
       "2098    3\n",
       "2059    2\n",
       "2709    2\n",
       "1470    1\n",
       "1856    2\n",
       "1444    1\n",
       "1438    1\n",
       "392     2\n",
       "1293    1\n",
       "325     2\n",
       "2636    3\n",
       "2276    2\n",
       "952     1\n",
       "771     1\n",
       "2854    3\n",
       "347     2\n",
       "117     2\n",
       "69      3\n",
       "225     2\n",
       "1004    2\n",
       "1368    2\n",
       "599     1\n",
       "1556    3\n",
       "808     3\n",
       "608     2\n",
       "2246    1\n",
       "2961    3\n",
       "352     1\n",
       "2419    2\n",
       "1722    1\n",
       "2051    3\n",
       "1522    1\n",
       "1732    2\n",
       "85      1\n",
       "2999    2\n",
       "1383    2\n",
       "691     2\n",
       "896     2\n",
       "2908    1\n",
       "1372    3\n",
       "78      1\n",
       "2497    1\n",
       "249     3\n",
       "2049    2\n",
       "1837    1\n",
       "530     1\n",
       "1275    1\n",
       "228     1\n",
       "2106    1\n",
       "2006    2\n",
       "2537    2\n",
       "436     1\n",
       "2381    3\n",
       "32      2\n",
       "394     3\n",
       "339     1\n",
       "832     3\n",
       "1412    2\n",
       "949     3\n",
       "1919    2\n",
       "1763    1\n",
       "1072    1\n",
       "2456    2\n",
       "2865    3\n",
       "2363    1\n",
       "1009    1\n",
       "1971    2\n",
       "73      2\n",
       "2359    2\n",
       "1451    2\n",
       "2165    3\n",
       "158     2\n",
       "2748    2\n",
       "2056    2\n",
       "579     3\n",
       "1234    1\n",
       "334     1\n",
       "1255    3\n",
       "1296    2\n",
       "1784    1\n",
       "1875    2\n",
       "1339    2\n",
       "1186    1\n",
       "1791    2\n",
       "2455    1\n",
       "1842    2\n",
       "861     2\n",
       "1409    2\n",
       "757     1\n",
       "2203    1\n",
       "1114    1\n",
       "576     1\n",
       "1126    3\n",
       "1715    1\n",
       "1742    2\n",
       "2226    3\n",
       "1804    3\n",
       "593     1\n",
       "375     1\n",
       "2476    3\n",
       "2567    3\n",
       "1908    3\n",
       "1779    1\n",
       "1427    2\n",
       "314     2\n",
       "270     1\n",
       "147     2\n",
       "1576    2\n",
       "1176    1\n",
       "868     3\n",
       "2966    2\n",
       "1517    3\n",
       "300     2\n",
       "632     3\n",
       "1887    2\n",
       "1871    2\n",
       "974     3\n",
       "2512    3\n",
       "2554    1\n",
       "631     1\n",
       "2765    3\n",
       "479     1\n",
       "2338    1\n",
       "2450    3\n",
       "1863    1\n",
       "981     3\n",
       "2552    1\n",
       "1540    2\n",
       "374     2\n",
       "1257    3\n",
       "171     1\n",
       "748     2\n",
       "2833    1\n",
       "1967    1\n",
       "1878    2\n",
       "356     1\n",
       "499     1\n",
       "935     3\n",
       "1212    2\n",
       "2168    3\n",
       "1181    1\n",
       "2358    1\n",
       "2367    2\n",
       "1346    2\n",
       "2399    3\n",
       "1627    3\n",
       "649     2\n",
       "793     2\n",
       "2342    1\n",
       "2362    3\n",
       "2917    3\n",
       "2825    2\n",
       "1095    3\n",
       "2933    1\n",
       "1400    1\n",
       "2648    1\n",
       "115     1\n",
       "2545    2\n",
       "1410    1\n",
       "362     1\n",
       "956     1\n",
       "1949    1\n",
       "329     1\n",
       "223     1\n",
       "1526    2\n",
       "865     2\n",
       "1462    1\n",
       "2895    3\n",
       "382     3\n",
       "1686    1\n",
       "1043    2\n",
       "2513    3\n",
       "1680    1\n",
       "304     1\n",
       "1776    1\n",
       "2845    2\n",
       "97      3\n",
       "1496    2\n",
       "2272    2\n",
       "2538    3\n",
       "2710    1\n",
       "230     2\n",
       "2925    3\n",
       "1961    2\n",
       "439     2\n",
       "299     2\n",
       "1016    3\n",
       "372     1\n",
       "1521    3\n",
       "1631    1\n",
       "1612    3\n",
       "1399    3\n",
       "1497    1\n",
       "1151    2\n",
       "1552    3\n",
       "2646    2\n",
       "90      2\n",
       "2575    1\n",
       "406     2\n",
       "144     1\n",
       "100     2\n",
       "2067    2\n",
       "1667    1\n",
       "2213    1\n",
       "269     3\n",
       "2670    3\n",
       "2414    2\n",
       "1224    2\n",
       "2744    2\n",
       "337     2\n",
       "777     2\n",
       "1076    1\n",
       "2360    1\n",
       "2690    1\n",
       "2728    1\n",
       "422     2\n",
       "1929    2\n",
       "2860    3\n",
       "135     1\n",
       "648     1\n",
       "2210    2\n",
       "1736    3\n",
       "1210    3\n",
       "857     1\n",
       "1764    3\n",
       "615     1\n",
       "707     2\n",
       "42      3\n",
       "575     2\n",
       "200     3\n",
       "1140    2\n",
       "393     1\n",
       "918     3\n",
       "1424    2\n",
       "71      2\n",
       "1641    2\n",
       "177     1\n",
       "1442    1\n",
       "1755    1\n",
       "2782    3\n",
       "592     2\n",
       "298     1\n",
       "1658    2\n",
       "994     2\n",
       "1884    3\n",
       "1939    1\n",
       "145     2\n",
       "433     3\n",
       "1675    2\n",
       "1312    2\n",
       "2202    2\n",
       "2459    2\n",
       "2929    2\n",
       "799     2\n",
       "2876    3\n",
       "922     3\n",
       "2356    2\n",
       "244     1\n",
       "1535    3\n",
       "246     1\n",
       "456     1\n",
       "1335    1\n",
       "2536    1\n",
       "2325    1\n",
       "2105    3\n",
       "520     2\n",
       "901     2\n",
       "2671    2\n",
       "875     1\n",
       "2267    1\n",
       "2195    3\n",
       "2148    2\n",
       "384     3\n",
       "1558    2\n",
       "2467    1\n",
       "1347    1\n",
       "277     1\n",
       "1291    1\n",
       "938     3\n",
       "1159    2\n",
       "873     1\n",
       "2396    3\n",
       "1398    1\n",
       "400     1\n",
       "       ..\n",
       "1310    2\n",
       "132     2\n",
       "1979    3\n",
       "2699    1\n",
       "1752    1\n",
       "2997    2\n",
       "1354    1\n",
       "528     3\n",
       "709     2\n",
       "1122    3\n",
       "308     2\n",
       "2912    2\n",
       "886     2\n",
       "889     2\n",
       "1475    2\n",
       "2593    3\n",
       "118     3\n",
       "2529    1\n",
       "1087    1\n",
       "1020    1\n",
       "140     2\n",
       "1329    2\n",
       "2692    3\n",
       "1015    3\n",
       "498     2\n",
       "879     1\n",
       "2435    2\n",
       "2457    3\n",
       "928     2\n",
       "258     1\n",
       "1174    3\n",
       "2254    1\n",
       "1363    2\n",
       "1060    3\n",
       "2101    3\n",
       "556     3\n",
       "179     1\n",
       "1821    1\n",
       "1246    1\n",
       "549     1\n",
       "1905    2\n",
       "619     3\n",
       "2258    1\n",
       "2178    3\n",
       "1460    1\n",
       "1490    3\n",
       "2614    2\n",
       "776     3\n",
       "828     1\n",
       "1906    2\n",
       "1358    2\n",
       "283     3\n",
       "1859    1\n",
       "77      2\n",
       "2146    1\n",
       "1688    2\n",
       "176     3\n",
       "834     3\n",
       "1309    1\n",
       "323     1\n",
       "1032    2\n",
       "942     2\n",
       "1846    1\n",
       "693     2\n",
       "2562    3\n",
       "2732    3\n",
       "153     2\n",
       "2909    2\n",
       "1090    1\n",
       "1524    3\n",
       "291     1\n",
       "194     3\n",
       "853     2\n",
       "903     3\n",
       "1899    2\n",
       "2329    1\n",
       "2388    2\n",
       "583     1\n",
       "2189    2\n",
       "2622    1\n",
       "1387    1\n",
       "1262    2\n",
       "426     2\n",
       "459     1\n",
       "2873    1\n",
       "1456    3\n",
       "516     1\n",
       "116     3\n",
       "1620    3\n",
       "331     2\n",
       "1580    3\n",
       "742     2\n",
       "1326    3\n",
       "2723    2\n",
       "745     1\n",
       "2631    3\n",
       "1290    1\n",
       "1334    1\n",
       "2579    1\n",
       "1650    2\n",
       "241     1\n",
       "1944    1\n",
       "466     2\n",
       "733     1\n",
       "1282    3\n",
       "54      1\n",
       "2884    2\n",
       "2894    2\n",
       "1425    3\n",
       "2759    2\n",
       "2352    2\n",
       "1064    3\n",
       "461     3\n",
       "1051    1\n",
       "2002    1\n",
       "2939    2\n",
       "1845    2\n",
       "2066    1\n",
       "83      2\n",
       "2543    1\n",
       "2726    1\n",
       "2867    2\n",
       "2927    3\n",
       "1909    1\n",
       "343     1\n",
       "2410    2\n",
       "1671    1\n",
       "2758    1\n",
       "164     3\n",
       "804     1\n",
       "358     3\n",
       "2500    1\n",
       "252     3\n",
       "2578    3\n",
       "1590    1\n",
       "792     2\n",
       "1305    2\n",
       "1570    1\n",
       "1058    2\n",
       "2378    1\n",
       "1455    2\n",
       "2369    1\n",
       "2031    1\n",
       "2044    2\n",
       "2349    3\n",
       "448     1\n",
       "2794    2\n",
       "2433    1\n",
       "2906    1\n",
       "1649    1\n",
       "2846    1\n",
       "607     3\n",
       "1263    1\n",
       "1661    2\n",
       "2332    2\n",
       "493     2\n",
       "767     2\n",
       "627     1\n",
       "532     2\n",
       "2401    1\n",
       "2739    1\n",
       "1768    2\n",
       "1677    1\n",
       "2138    1\n",
       "1912    1\n",
       "2449    3\n",
       "131     3\n",
       "1617    1\n",
       "2294    1\n",
       "2091    3\n",
       "2145    2\n",
       "939     3\n",
       "1278    2\n",
       "788     3\n",
       "1217    3\n",
       "27      1\n",
       "1925    3\n",
       "866     3\n",
       "238     3\n",
       "2354    3\n",
       "359     2\n",
       "2569    3\n",
       "2160    2\n",
       "2279    2\n",
       "2592    1\n",
       "440     1\n",
       "2915    3\n",
       "2742    3\n",
       "1267    3\n",
       "1435    3\n",
       "2458    1\n",
       "2836    2\n",
       "1531    1\n",
       "2547    1\n",
       "763     2\n",
       "728     3\n",
       "286     3\n",
       "594     1\n",
       "717     3\n",
       "29      1\n",
       "494     1\n",
       "236     1\n",
       "435     1\n",
       "1341    1\n",
       "1674    2\n",
       "2417    1\n",
       "2234    2\n",
       "1146    2\n",
       "198     1\n",
       "557     3\n",
       "1646    3\n",
       "835     2\n",
       "1544    1\n",
       "2077    2\n",
       "683     1\n",
       "1377    2\n",
       "168     1\n",
       "1316    2\n",
       "2993    1\n",
       "1867    3\n",
       "203     1\n",
       "740     1\n",
       "1150    2\n",
       "1428    2\n",
       "1005    2\n",
       "1295    1\n",
       "256     2\n",
       "285     2\n",
       "2585    2\n",
       "2914    1\n",
       "867     2\n",
       "959     1\n",
       "1575    2\n",
       "2871    2\n",
       "451     1\n",
       "2995    2\n",
       "2072    3\n",
       "2499    3\n",
       "1006    3\n",
       "319     2\n",
       "376     1\n",
       "1829    1\n",
       "1644    2\n",
       "1362    2\n",
       "1268    1\n",
       "2932    1\n",
       "509     1\n",
       "2582    3\n",
       "2949    2\n",
       "716     3\n",
       "511     2\n",
       "2372    1\n",
       "2743    1\n",
       "1489    2\n",
       "1528    2\n",
       "103     2\n",
       "1545    3\n",
       "2440    1\n",
       "1685    2\n",
       "143     1\n",
       "681     3\n",
       "654     2\n",
       "2937    1\n",
       "545     3\n",
       "1084    1\n",
       "1105    2\n",
       "1001    2\n",
       "670     3\n",
       "2011    2\n",
       "989     2\n",
       "455     1\n",
       "765     3\n",
       "1629    3\n",
       "1995    1\n",
       "2337    2\n",
       "2771    2\n",
       "2553    1\n",
       "2516    1\n",
       "2580    1\n",
       "2259    1\n",
       "1153    1\n",
       "1586    1\n",
       "2164    1\n",
       "2740    2\n",
       "2005    3\n",
       "1199    2\n",
       "550     3\n",
       "1392    2\n",
       "243     1\n",
       "2394    3\n",
       "1338    1\n",
       "2404    2\n",
       "1145    3\n",
       "1901    1\n",
       "383     2\n",
       "2223    1\n",
       "2519    1\n",
       "1956    1\n",
       "586     1\n",
       "1426    2\n",
       "2245    2\n",
       "1208    2\n",
       "469     1\n",
       "1243    3\n",
       "2984    3\n",
       "2556    2\n",
       "1885    3\n",
       "518     1\n",
       "539     3\n",
       "1285    3\n",
       "2108    2\n",
       "591     1\n",
       "1969    3\n",
       "1818    2\n",
       "67      1\n",
       "1166    1\n",
       "2085    3\n",
       "2224    1\n",
       "1010    3\n",
       "2428    3\n",
       "2667    1\n",
       "666     1\n",
       "881     3\n",
       "2730    3\n",
       "1466    1\n",
       "1287    2\n",
       "188     2\n",
       "588     1\n",
       "50      1\n",
       "2505    1\n",
       "231     1\n",
       "2211    1\n",
       "1327    1\n",
       "2962    3\n",
       "1416    1\n",
       "335     2\n",
       "546     1\n",
       "2641    1\n",
       "1369    1\n",
       "2893    1\n",
       "2280    3\n",
       "1237    2\n",
       "1364    2\n",
       "2847    1\n",
       "1663    1\n",
       "502     1\n",
       "2896    1\n",
       "416     3\n",
       "136     3\n",
       "280     1\n",
       "2674    2\n",
       "660     2\n",
       "429     2\n",
       "2768    1\n",
       "396     1\n",
       "2060    1\n",
       "3       1\n",
       "2494    1\n",
       "985     2\n",
       "2143    1\n",
       "397     3\n",
       "2380    2\n",
       "2306    3\n",
       "1121    3\n",
       "483     1\n",
       "2741    2\n",
       "2881    1\n",
       "677     3\n",
       "705     3\n",
       "402     1\n",
       "995     3\n",
       "1342    2\n",
       "8       2\n",
       "1448    3\n",
       "795     2\n",
       "2080    1\n",
       "747     1\n",
       "1532    1\n",
       "72      3\n",
       "1047    3\n",
       "1790    2\n",
       "2292    2\n",
       "430     1\n",
       "1719    2\n",
       "1196    3\n",
       "1433    1\n",
       "1017    3\n",
       "524     2\n",
       "924     1\n",
       "2903    2\n",
       "2757    1\n",
       "1396    2\n",
       "1527    2\n",
       "643     3\n",
       "441     1\n",
       "2019    2\n",
       "1968    1\n",
       "1943    2\n",
       "1028    3\n",
       "1916    2\n",
       "1832    1\n",
       "2052    1\n",
       "1037    1\n",
       "1345    2\n",
       "1607    2\n",
       "2480    1\n",
       "2229    1\n",
       "2974    1\n",
       "969     2\n",
       "923     3\n",
       "1708    1\n",
       "161     1\n",
       "2220    2\n",
       "1600    1\n",
       "481     1\n",
       "1955    3\n",
       "2180    3\n",
       "1373    1\n",
       "838     3\n",
       "1132    3\n",
       "1415    2\n",
       "675     3\n",
       "2065    1\n",
       "2678    1\n",
       "1453    1\n",
       "2628    3\n",
       "1625    3\n",
       "1609    2\n",
       "1452    2\n",
       "1308    3\n",
       "2252    2\n",
       "355     2\n",
       "1602    2\n",
       "5       2\n",
       "152     1\n",
       "1081    2\n",
       "543     3\n",
       "229     1\n",
       "2989    3\n",
       "1393    1\n",
       "755     3\n",
       "186     3\n",
       "1303    2\n",
       "2985    2\n",
       "2738    2\n",
       "1506    1\n",
       "737     2\n",
       "2952    2\n",
       "1648    1\n",
       "1731    1\n",
       "403     1\n",
       "2618    2\n",
       "1748    3\n",
       "1861    1\n",
       "2829    3\n",
       "1099    1\n",
       "2097    1\n",
       "1023    3\n",
       "2535    3\n",
       "266     1\n",
       "2111    1\n",
       "616     3\n",
       "2900    1\n",
       "1493    1\n",
       "978     2\n",
       "2695    2\n",
       "462     2\n",
       "1814    1\n",
       "1659    2\n",
       "2565    2\n",
       "2004    2\n",
       "1758    1\n",
       "2956    2\n",
       "2601    3\n",
       "548     2\n",
       "1596    1\n",
       "2634    2\n",
       "1500    2\n",
       "2465    2\n",
       "1696    1\n",
       "2471    2\n",
       "321     1\n",
       "852     1\n",
       "2022    1\n",
       "2423    2\n",
       "327     1\n",
       "1548    1\n",
       "2875    2\n",
       "2269    1\n",
       "1235    3\n",
       "2706    1\n",
       "1813    2\n",
       "2938    1\n",
       "2855    3\n",
       "510     2\n",
       "936     2\n",
       "1809    2\n",
       "1155    1\n",
       "2954    1\n",
       "346     2\n",
       "Name: Label_num, Length: 3001, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pickle.load(open('features/1-1_char_gram.pickle', 'rb'))['y_test']\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_dict = {}\n",
    "count = 0\n",
    "total = len(list(top_char_features['Feature']) + \\\n",
    "            list(top_word_features['Feature']) + \\\n",
    "            list(top_punctuation_features['Feature']) + \\\n",
    "            list(top_capital_features['Feature']))\n",
    "\n",
    "for feature in list(top_char_features['Feature']) + \\\n",
    "            list(top_word_features['Feature']) + \\\n",
    "            list(top_punctuation_features['Feature']) + \\\n",
    "            list(top_capital_features['Feature']):\n",
    "    file = feature+'.pickle'\n",
    "    print(feature)\n",
    "    if os.path.isfile(os.path.join('results/', file)):\n",
    "        #load the classifier\n",
    "        data_dict[feature] = [pickle.load(open(os.path.join('results/', file), 'rb'))['SVM'][0]]\n",
    "        print(\"Loading of classfier successful!\")\n",
    "        #load the X_train\n",
    "        if os.path.isfile(os.path.join('features/', file)):\n",
    "            X_test = pickle.load(open(os.path.join('features/', file), 'rb'))['X_test']\n",
    "        elif os.path.isfile(os.path.join('extra_features/', file)):\n",
    "            X_test = pickle.load(open(os.path.join('extra_features/', file), 'rb'))['X_test']\n",
    "        print(\"Loading of X_test successful!\")\n",
    "        %time data_dict[feature].append(data_dict[feature][0].predict(X_test.toarray()))\n",
    "    elif os.path.isfile(os.path.join('results/SVM/', file)):\n",
    "        #load the classifier\n",
    "        data_dict[feature] = [pickle.load(open(os.path.join('results/SVM/', file), 'rb'))['SVM'][0]]\n",
    "        print(\"Loading of classfier successful!\")\n",
    "        #load the X_train\n",
    "        if os.path.isfile(os.path.join('features/', file)):\n",
    "            X_test = pickle.load(open(os.path.join('features/', file), 'rb'))['X_test']\n",
    "        elif os.path.isfile(os.path.join('extra_features/', file)):\n",
    "            X_test = pickle.load(open(os.path.join('extra_features/', file), 'rb'))['X_test']\n",
    "        print(\"Loading of X_test successful!\")\n",
    "        %time data_dict[feature].append(data_dict[feature][0].predict(X_test.toarray()))\n",
    "    else:\n",
    "        raise Exception(file + \" not found in either folder.\")\n",
    "    count += 1\n",
    "    print(\"Done {} out of {}\".format(count, total), end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.56 s, sys: 24.4 s, total: 31 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%time data_dict = pickle.load(open(\"bagging.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_likely_prediction(prediction_list, likelihood):\n",
    "    outcome = [0] * (max(prediction_list) + 10)\n",
    "    maxy = 0\n",
    "    for i in range(len(prediction_list)):\n",
    "        outcome[prediction_list[i]] += likelihood[i]\n",
    "        if outcome[prediction_list[i]] > outcome[maxy]:\n",
    "            maxy = prediction_list[i]\n",
    "    return maxy\n",
    "    \n",
    "\n",
    "def analyse_and_show(prediction_list):\n",
    "#     truth_serum_1 = (prediction_1 == y_test)\n",
    "#     truth_serum_2 = (prediction_2 == y_test)\n",
    "#     truth_serum_3 = (prediction_3 == y_test)\n",
    "    truth_serum_list = [(prediction == y_test) for prediction in prediction_list]\n",
    "    likelihood_list = [np.sum(serum)/len(serum) for serum in truth_serum_list]\n",
    "#     common_true = 0\n",
    "#     common_false = 0\n",
    "#     first_true_only = 0\n",
    "#     second_true_only = 0\n",
    "#     for i in range(len(truth_serum_1)):\n",
    "#         if truth_serum_1[i] and truth_serum_2[i]:\n",
    "#             common_true += 1\n",
    "#         elif not truth_serum_1[i] and not truth_serum_2[i]:\n",
    "#             common_false += 1\n",
    "#         elif truth_serum_1[i] and not truth_serum_2[i]:\n",
    "#             first_true_only += 1\n",
    "#         elif not truth_serum_1[i] and truth_serum_2[i]:\n",
    "#             second_true_only += 1\n",
    "#     print(\"{}\\t{}\\t{}\\t{}\\n\".format(common_true, common_false, first_true_only, second_true_only))\n",
    "#     final_serum = np.sum(np.ndarray(list(map(lambda x: most_likely_prediction(x, likelihood_list), prediction_list))) == y_test)\n",
    "    final_serum = [most_likely_prediction([prediction_list[0][i], prediction_list[1][i], prediction_list[2][i]], likelihood_list) for i in range(len(prediction_list[0]))]\n",
    "    final_serum = (np.array(final_serum) == y_test)\n",
    "    return np.sum(final_serum), [np.sum(serum) for serum in truth_serum_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1-5_char_gram', '1-6_char_gram', '2-5_char_gram')\n",
      "(1761, [1757, 1747, 1741])\n",
      "('1-5_char_gram', 'char_4_gram_non_alphabet', 'unigram')\n",
      "(1761, [1757, 1264, 1712])\n",
      "CPU times: user 17.4 s, sys: 60 ms, total: 17.4 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "for combo in combinations(data_dict.keys(), 3):\n",
    "    result = analyse_and_show([data_dict[feature][1] for feature in combo])\n",
    "    if result[0] > 1760:\n",
    "        print(combo)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capitals_char_2_gram\n",
      "Accuracy:  0.422525824725\n",
      "F1 score:  0.31209357838\n",
      "0.422525824725 / 3001\n",
      "\n",
      "\n",
      "\n",
      "1-5_char_gram\n",
      "Accuracy:  0.585471509497\n",
      "F1 score:  0.579501600226\n",
      "0.585471509497 / 3001\n",
      "\n",
      "\n",
      "\n",
      "1-6_char_gram\n",
      "Accuracy:  0.582139286904\n",
      "F1 score:  0.57630130703\n",
      "0.582139286904 / 3001\n",
      "\n",
      "\n",
      "\n",
      "capitals_char_1_gram\n",
      "Accuracy:  0.41586137954\n",
      "F1 score:  0.307479134525\n",
      "0.41586137954 / 3001\n",
      "\n",
      "\n",
      "\n",
      "2-5_char_gram\n",
      "Accuracy:  0.580139953349\n",
      "F1 score:  0.574087567708\n",
      "0.580139953349 / 3001\n",
      "\n",
      "\n",
      "\n",
      "char_4_gram_non_alphabet\n",
      "Accuracy:  0.421192935688\n",
      "F1 score:  0.320689528553\n",
      "0.421192935688 / 3001\n",
      "\n",
      "\n",
      "\n",
      "char_1_gram_non_alphabet\n",
      "Accuracy:  0.426524491836\n",
      "F1 score:  0.324395387394\n",
      "0.426524491836 / 3001\n",
      "\n",
      "\n",
      "\n",
      "char_3_gram_non_alphabet\n",
      "Accuracy:  0.422859046984\n",
      "F1 score:  0.326939126116\n",
      "0.422859046984 / 3001\n",
      "\n",
      "\n",
      "\n",
      "1-2_gram_without_stopwords\n",
      "Accuracy:  0.571142952349\n",
      "F1 score:  0.563551092852\n",
      "0.571142952349 / 3001\n",
      "\n",
      "\n",
      "\n",
      "capitals_char_4_gram\n",
      "Accuracy:  0.41586137954\n",
      "F1 score:  0.257282314998\n",
      "0.41586137954 / 3001\n",
      "\n",
      "\n",
      "\n",
      "unigram\n",
      "Accuracy:  0.570476507831\n",
      "F1 score:  0.56334703573\n",
      "0.570476507831 / 3001\n",
      "\n",
      "\n",
      "\n",
      "char_2_gram_non_alphabet\n",
      "Accuracy:  0.425858047318\n",
      "F1 score:  0.333259333923\n",
      "0.425858047318 / 3001\n",
      "\n",
      "\n",
      "\n",
      "capitals_char_3_gram\n",
      "Accuracy:  0.427857380873\n",
      "F1 score:  0.310054275714\n",
      "0.427857380873 / 3001\n",
      "\n",
      "\n",
      "\n",
      "1-2_gram\n",
      "Accuracy:  0.576141286238\n",
      "F1 score:  0.569729315748\n",
      "0.576141286238 / 3001\n",
      "\n",
      "\n",
      "\n",
      "1-4_gram_without_stopwords\n",
      "Accuracy:  0.571809396868\n",
      "F1 score:  0.564258431728\n",
      "0.571809396868 / 3001\n",
      "\n",
      "\n",
      "\n",
      "2-6_char_gram\n",
      "Accuracy:  0.577807397534\n",
      "F1 score:  0.571626759979\n",
      "0.577807397534 / 3001\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Abhor/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for feature in data_dict:\n",
    "    y_pred = data_dict[feature][1]\n",
    "    print(feature)\n",
    "    print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
    "    print(\"F1 score: \", f1_score(y_pred=y_pred, y_true=y_test, average='weighted'))\n",
    "#     print(confusion_matrix(y_pred=data_dict[feature][1], y_true=y_test))\n",
    "#     a = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "#     print(a[0][0] + a[1][1] + a[2][2])\n",
    "    print(np.sum((y_pred) == (y_test))/len(y_pred), '/', len(y_pred))\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
